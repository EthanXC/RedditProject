{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EthanXC/RedditProject/blob/main/RedditProject1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "jOusy2TIyNIr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "589dd423-4413-4c6e-a916-0d3de77ccb85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-59ab05e21164>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIrtpElvsU0o"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "# FYI the accellerate -u is very important to avoid version issues with torch\n",
        "!pip install transformers\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "YLGieoJQsjtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"fddemarco/pushshift-reddit-comments\", streaming = True)"
      ],
      "metadata": {
        "id": "DLalym2Ltadt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "S0Ip9rmPt3_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(dataset['train'])\n"
      ],
      "metadata": {
        "id": "4b84IBMfvuzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_data = next(it)\n",
        "#print(extract_data)\n",
        "\n",
        "print(extract_data['body'])\n",
        "#testing if we can get a sample comment"
      ],
      "metadata": {
        "id": "Urlwih5kL5Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'column1_name': ['text'],\n",
        "    'column2_name': ['score'],\n",
        "    'column3_name': ['labels']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "VU3cwFhKxDwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty DataFrame with columns\n",
        "df = pd.DataFrame(columns=['text', 'score', 'labels'])\n",
        "\n",
        "nsfw_keywords = ['nsfw', 'adult', 'sex', 'porn', 'xxx', 'gonewild', 'nudes', 'slut', 'WTF',\n",
        "'hentai', 'cum', 'rule34', 'pussy', 'onlyfans', 'milf', 'nude', 'boob']\n",
        "\n",
        "for i in range(10000):  # only 10,000 rows\n",
        "    extract_data = next(it)\n",
        "    text = extract_data['body']\n",
        "    score = extract_data['score']\n",
        "    labels = extract_data['subreddit']\n",
        "\n",
        "    if any(keyword in labels.lower() for keyword in nsfw_keywords):\n",
        "      continue\n",
        "\n",
        "    new_row_data = {'text': text, \"score\": score, \"labels\": labels}\n",
        "    df.loc[len(df)] = new_row_data\n",
        "\n",
        "    if i % 1000 == 0:\n",
        "        print(i)\n",
        "        print(new_row_data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F65fGpqgLgai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "U58GPvchIMvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = dict(enumerate(set(df['labels'])))"
      ],
      "metadata": {
        "id": "MQfMxKSCICcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "id": "4OmgzbKxIDz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "FRW-EFBJzPyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# Load DistilBERT model and tokenizer filling out the code below based on the documentation HINT: Click on on use in transformers and the code will be there\n",
        "#model_name = \"Roberta model\"# code unnessisary but I like to use it to store the string name to make the code cleaner\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels = len(id2label))\n"
      ],
      "metadata": {
        "id": "F3O0vH7vRuSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows = df[df.isna().T.any().T]\n",
        "nan_rows.head()"
      ],
      "metadata": {
        "id": "l-C-25lx7zQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_rows = df[df.isnull().any(axis=1)]\n",
        "null_rows.head()"
      ],
      "metadata": {
        "id": "O6ALVng15RxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if np.isinf(df['score']).any():\n",
        "  print(\"HELLO\")"
      ],
      "metadata": {
        "id": "jjbniwLm5vM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "Mlbnimwd765B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LcrNsp_0Ws3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#TODO: Complete this line using the train_test_split function and set the test size to .21\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df['text'], df['labels'], test_size=0.21)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
        "# Reset the index\n",
        "train_texts, train_labels = train_texts.reset_index(drop=True), train_labels.reset_index(drop=True)\n",
        "val_texts, val_labels = val_texts.reset_index(drop=True), val_labels.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "exYOU14h79PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, return_tensors = \"pt\")\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "VeTFkeY_8NZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "id": "0GJ2Wduqyt9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label_reversed = {v: k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "UBmnc7lwXLee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label_reversed #word:number"
      ],
      "metadata": {
        "id": "h2sfDi4ZXWrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as pt\n",
        "\n",
        "class SpamDataset(pt.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels.values\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: pt.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if len(self.labels) > 0:  # Check if labels array has any elements\n",
        "            labels = self.labels[idx]\n",
        "            print(labels)\n",
        "            labels_converted = id2label_reversed[labels]\n",
        "            print(labels_converted)\n",
        "            item[\"labels\"] = pt.tensor(labels_converted)\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        print(len(self.labels))\n",
        "        return len(self.labels)\n",
        "\n",
        "def list_of_dicts_to_dict_of_lists(d):\n",
        "  dic = d[0]\n",
        "  keys = dic.keys()\n",
        "  values = [dic.values() for dic in d]\n",
        "  return {k: list(v) for k,v in zip(keys, zip(*values))}"
      ],
      "metadata": {
        "id": "EKbLvr4b8SlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_Dataset = SpamDataset(train_encodings, train_labels)\n"
      ],
      "metadata": {
        "id": "wyNlqi6o8gni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Val_Dataset = SpamDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "zsOr3bzx8oKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers torch evaluate nltk rouge_score"
      ],
      "metadata": {
        "id": "-ZH7OXsO8zMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import evaluate\n"
      ],
      "metadata": {
        "id": "yN30VuYI8tQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n"
      ],
      "metadata": {
        "id": "7uSrVUdE8uXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%set_env CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "HwY09Fscb2aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUDA_LAUNCH_BLOCKING"
      ],
      "metadata": {
        "id": "uB5nuHj7K989"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=1,              # total number of training epochs, let's try 1 for now\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = Train_Dataset,\n",
        "    eval_dataset = Val_Dataset,\n",
        "    compute_metrics = compute_metrics\n",
        "    #TODO: figure out what 5 params we need here. There should be 5 and the last is how we compute the metrics later . . .\n",
        ")"
      ],
      "metadata": {
        "id": "h62xDRbT8vQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set(id2label_reversed.values)"
      ],
      "metadata": {
        "id": "LKySG-y2Jchb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Train the model (HINT: this is 1 short line of code just calling the trainer)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "TQ2Ec2ji82qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO use the evaluate method on the trainer to get and print the results. Feel free to look at Huggingface Docs\n",
        "results = trainer.evaluate()"
      ],
      "metadata": {
        "id": "jbyI1fiW84lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Save the model\n",
        "trainer.save_model('my_model')"
      ],
      "metadata": {
        "id": "dtlW8CVc86Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Now to finish off I want you to load the model you trained and saved and write a fake spam email for it mthen have the model classify it\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"my_model\")\n",
        "msg = \"I want to download minecraft mods\"\n",
        "msg_encodings = tokenizer(msg, truncation=True, padding=True, return_tensors = \"pt\")\n",
        "\n",
        "outputs = model(**msg_encodings)\n",
        "print(f\"outputs: {outputs}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QQHdHwP88774"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.logits.shape"
      ],
      "metadata": {
        "id": "EDJkle-YOEsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(id2label)"
      ],
      "metadata": {
        "id": "HunaCiQsPKoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = torch.softmax(outputs.logits[0], dim = 0 )\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "4yntV1-AN3Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sort_prob = probabilities.sort(descending = True)"
      ],
      "metadata": {
        "id": "M99eIYos8_lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sort_prob)"
      ],
      "metadata": {
        "id": "5ibnkGvROqTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_out_top_x_probs(probs, x):\n",
        "  print('Here are the top 10 most subreddits with similar')\n",
        "  for n in range(x):\n",
        "    sort_probs = probs\n",
        "    tensor_probs = sort_probs.values[n]\n",
        "    index = sort_probs.indices[n]\n",
        "    sort_prob_index_int = index.item()\n",
        "    subreddit_string = id2label[sort_prob_index_int]\n",
        "    print(f'{n+1}. {subreddit_string} ({tensor_probs * 100}%)')"
      ],
      "metadata": {
        "id": "7Zlnb0t_Osvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_out_top_x_probs(sort_prob, 10)"
      ],
      "metadata": {
        "id": "hpINnblxfnyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it's time to graph!\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    precision = precision_score(labels, predictions, average='weighted')\n",
        "    recall = recall_score(labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'accuracy': accuracy\n",
        "    }\n"
      ],
      "metadata": {
        "id": "YcnB-s5CnWVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# this is fake data, replace with real data\n",
        "epochs = 1\n",
        "loss = [0.30, 0.24, 0.20]\n",
        "f1_scores = [0.82, 0.85, 0.87]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plotting loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, loss, label='Training Loss', marker='o')\n",
        "plt.title('Training Loss per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Plotting F1 Score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, f1_scores, label='F1 Score', marker='o', color='r')\n",
        "plt.title('F1 Score per Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sDH9kGk1pKOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "03nWNXTEpIMX"
      }
    }
  ]
}